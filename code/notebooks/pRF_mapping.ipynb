{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67c07ccd",
   "metadata": {},
   "source": [
    "# Population receptive field mapping workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cbcc26a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'prfpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a698d0b0492e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjoin\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mprfpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstimulus\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPRFStimulus2D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mprfpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIso2DGaussianModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mprfpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIso2DGaussianFitter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'prfpy'"
     ]
    }
   ],
   "source": [
    "#!pip install fslpy\n",
    "import os\n",
    "import sys\n",
    "from os.path import join as opj\n",
    "\n",
    "from prfpy.stimulus import PRFStimulus2D\n",
    "from prfpy.model import Iso2DGaussianModel\n",
    "from prfpy.fit import Iso2DGaussianFitter\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import math \n",
    "import scipy\n",
    "\n",
    "import pickle\n",
    "\n",
    "from fsl.data.freesurfer import loadVertexDataFile\n",
    "from nilearn import image, surface, plotting, signal\n",
    "import nipype.interfaces.freesurfer as fs\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# # get nr of processing threads (based on slurm script)\n",
    "# n_procs = int(os.getenv('OMP_NUM_THREADS'))   \n",
    "# print(n_procs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf01702f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #!pip install freesurfer-surface\n",
    "# from freesurfer_surface import Surface, Vertex, Triangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bd87ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import generate_equivolumetric_surfaces.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea75251e",
   "metadata": {},
   "source": [
    "### Set data directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5949b437",
   "metadata": {},
   "outputs": [],
   "source": [
    "local = True\n",
    "debugging = False\n",
    "if not local:\n",
    "    slurm_run = False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca14d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get current sub and hem ids\n",
    "if local or (not local and not slurm_run):\n",
    "    sub_id        = 0\n",
    "    hem_id        = 0\n",
    "elif not local and slurm_run:\n",
    "    sub_id        = int(sys.argv[1])\n",
    "    hem_id        = int(sys.argv[2])\n",
    "\n",
    "\n",
    "# list of all sub and hem ids\n",
    "subject_list  = ['sub-01','sub-02','sub-03','sub-04']\n",
    "hem_list      = ['lh','rh']\n",
    "hem_text_list = ['left','right']\n",
    "\n",
    "# directories\n",
    "proj_id       = 'project-00-7t-pipeline-dev'\n",
    "if local:\n",
    "    proj_dir      = '/home/mayajas/scratch/'+proj_id+'/'\n",
    "    home_dir      = '/home/mayajas/Documents/'+proj_id+'/'\n",
    "    programs_dir  = '/home/mayajas/Documents/programs/'\n",
    "else:\n",
    "    proj_dir      = '/scratch/mayaaj90/'+proj_id+'/'\n",
    "    home_dir      = '/home/mayaaj90/projects/'+proj_id+'/'\n",
    "    programs_dir  = '/home/mayaaj90/programs/'\n",
    "    \n",
    "prfpy_dir     = opj(proj_dir,'output','prfpy',subject_list[sub_id])\n",
    "\n",
    "if subject_list[sub_id] == 'sub-04':\n",
    "    FS_dir       = opj(proj_dir,'derivatives','wf_advanced_skullstrip_sub-04',\n",
    "                       '_subject_id_'+subject_list[sub_id],'autorecon_pial')\n",
    "else:\n",
    "    FS_dir       = opj(proj_dir,'derivatives','wf_advanced_skullstrip',\n",
    "                       '_subject_id_'+subject_list[sub_id],'autorecon_pial')\n",
    "\n",
    "# set FS subjects dir\n",
    "os.environ[\"SUBJECTS_DIR\"] = FS_dir\n",
    "\n",
    "# add path to surface tools\n",
    "surface_tools_dir = opj(programs_dir,'surface_tools','equivolumetric_surfaces')\n",
    "sys.path.append(surface_tools_dir)\n",
    "\n",
    "# set working dir\n",
    "if os.getcwd() != opj(home_dir,'code','analysis-scripts','python'):\n",
    "    os.chdir(opj(home_dir,'code','analysis-scripts','python'))\n",
    "    \n",
    "# number of cores to use: either set explicitly or base on settings in slurm job file\n",
    "import os\n",
    "if local:\n",
    "    n_procs = 1\n",
    "else:\n",
    "    n_procs = int(os.getenv('OMP_NUM_THREADS'))   \n",
    "print(n_procs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920a0b01",
   "metadata": {},
   "source": [
    "### Input data filenames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5f628d",
   "metadata": {},
   "source": [
    "Image filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fb71e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pRF mapping runs \n",
    "n_runs           = 2\n",
    "bar1_nii_fn      = opj(prfpy_dir,'reg_bar1.nii')\n",
    "bar2_nii_fn      = opj(prfpy_dir,'reg_bar2.nii')\n",
    "\n",
    "# mean functional\n",
    "meanFunc_nii_fn  = opj(prfpy_dir,'reg_meanFunc.nii')\n",
    "\n",
    "# anatomical image\n",
    "T1_nii_fn        = opj(prfpy_dir,'T1_out.nii')\n",
    "\n",
    "# Freesurfer mesh filenames\n",
    "gm_surf_fn        = opj(FS_dir,subject_list[sub_id],'surf',hem_list[hem_id]+'.pial')\n",
    "wm_surf_fn        = opj(FS_dir,subject_list[sub_id],'surf',hem_list[hem_id]+'.white')\n",
    "\n",
    "inflated_surf_fn  = opj(FS_dir,subject_list[sub_id],'surf',hem_list[hem_id]+'.inflated')\n",
    "sulc_surf_fn      = opj(FS_dir,subject_list[sub_id],'surf',hem_list[hem_id]+'.sulc')\n",
    "\n",
    "# equivolumetric surface output filenames\n",
    "n_surfs           = 6  # number of equivolumetric surfaces (including pial and white)\n",
    "n_surfs_str       = str(n_surfs)\n",
    "\n",
    "equi_surf_fn_list = ['equi0.0.pial',\n",
    "                     'equi0.2.pial',\n",
    "                     'equi0.4.pial',\n",
    "                     'equi0.6.pial',\n",
    "                     'equi0.8.pial',\n",
    "                     'equi1.0.pial']\n",
    "# equi_surf0_fn     = opj(FS_dir,subject_list[sub_id],'surf',hem_list[hem_id]+'.equi0.0.pial')\n",
    "# equi_surf1_fn     = opj(FS_dir,subject_list[sub_id],'surf',hem_list[hem_id]+'.equi0.2.pial')\n",
    "# equi_surf2_fn     = opj(FS_dir,subject_list[sub_id],'surf',hem_list[hem_id]+'.equi0.4.pial')\n",
    "# equi_surf3_fn     = opj(FS_dir,subject_list[sub_id],'surf',hem_list[hem_id]+'.equi0.6.pial')\n",
    "# equi_surf4_fn     = opj(FS_dir,subject_list[sub_id],'surf',hem_list[hem_id]+'.equi0.8.pial')\n",
    "# equi_surf5_fn     = opj(FS_dir,subject_list[sub_id],'surf',hem_list[hem_id]+'.equi1.0.pial')\n",
    "\n",
    "# surface-projected functional runs\n",
    "meanFunc_mgh_fn  = opj(prfpy_dir,hem_list[hem_id]+'.meanFunc.mgh')\n",
    "bar_mgh_fn_list   = [[opj(prfpy_dir,hem_list[hem_id]+'.equi'+str(depth)+'.bar'+str(run+1)+'.mgh') \n",
    "                      for run in range(0,n_runs)]\n",
    "                     for depth in range(0,n_surfs)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0439be8",
   "metadata": {},
   "source": [
    "PRF output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f284920",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_fit_avg_fn      = opj(prfpy_dir,hem_list[hem_id]+'_grid_fit_avg.pckl')\n",
    "iterative_fit_avg_fn = opj(prfpy_dir,hem_list[hem_id]+'_iterative_fit_avg.pckl')\n",
    "pRF_param_avg_fn     = opj(prfpy_dir,hem_list[hem_id]+'_pRF_params_avg.pckl')\n",
    "\n",
    "\n",
    "grid_fit_per_depth_fn      = opj(prfpy_dir,hem_list[hem_id]+'_grid_fit_per_depth.pckl')\n",
    "iterative_fit_per_depth_fn = opj(prfpy_dir,hem_list[hem_id]+'_iterative_fit_per_depth.pckl')\n",
    "pRF_param_per_depth_fn     = opj(prfpy_dir,hem_list[hem_id]+'_pRF_params_per_depth.pckl')\n",
    "\n",
    "occ_mask_fn          = opj(prfpy_dir,hem_list[hem_id]+'_occ_mask.pckl')\n",
    "\n",
    "polar_map_mgh        = opj(prfpy_dir,hem_list[hem_id]+'.pol.mgh')\n",
    "ecc_map_mgh          = opj(prfpy_dir,hem_list[hem_id]+'.ecc.mgh')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015eb32f",
   "metadata": {},
   "source": [
    "### Generate equivolumetric surfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e736a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output      = hem_list[hem_id]+'.equi'\n",
    "equivol_path= opj(FS_dir,subject_list[sub_id],'surf',output+'0.0.pial')\n",
    "\n",
    "if not os.path.exists(equivol_path) and debugging:\n",
    "    os.system('python '+surface_tools_dir+'/generate_equivolumetric_surfaces.py --smoothing 0 --software ''freesurfer'' --subject_id ' + subject_list[sub_id] + ' ' + gm_surf_fn  + ' ' + wm_surf_fn  + ' ' + n_surfs_str  + ' ' + output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276dd29a",
   "metadata": {},
   "source": [
    "### Surface-project functional data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5f1f22",
   "metadata": {},
   "source": [
    "Mean functional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2e9d69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "depth = 0\n",
    "\n",
    "if not os.path.exists(meanFunc_mgh_fn) and debugging:\n",
    "    sampler = fs.SampleToSurface(hemi=hem_list[hem_id])\n",
    "    sampler.inputs.source_file = meanFunc_nii_fn\n",
    "    sampler.inputs.reg_header = True\n",
    "    sampler.inputs.subjects_dir = FS_dir\n",
    "    sampler.inputs.subject_id = subject_list[sub_id]\n",
    "    sampler.inputs.sampling_method = \"point\"\n",
    "    sampler.inputs.sampling_range = 0.0\n",
    "    sampler.inputs.sampling_units = \"mm\"\n",
    "    sampler.inputs.surface = equi_surf_fn_list[depth]\n",
    "    sampler.inputs.out_file = meanFunc_mgh_fn\n",
    "\n",
    "    if n_procs == 1:\n",
    "        sampler.run()\n",
    "    else:\n",
    "        sampler.run('MultiProc', plugin_args={'n_procs': n_procs})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03491fce",
   "metadata": {},
   "source": [
    "Bar runs (iterating over bar run and equivolumetric surface depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0081f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "for depth in range(0,n_surfs):\n",
    "    for run in range(0,n_runs):\n",
    "        if not os.path.exists(bar_mgh_fn_list[depth][run]):\n",
    "            display(bar_mgh_fn_list[depth][run])\n",
    "            sampler = fs.SampleToSurface(hemi=hem_list[hem_id])\n",
    "            if run == 0:\n",
    "                sampler.inputs.source_file = bar1_nii_fn\n",
    "            elif run == 1:\n",
    "                sampler.inputs.source_file = bar2_nii_fn\n",
    "            sampler.inputs.reg_header = True\n",
    "            sampler.inputs.subjects_dir = FS_dir\n",
    "            sampler.inputs.subject_id = subject_list[sub_id]\n",
    "            sampler.inputs.sampling_method = \"point\"\n",
    "            sampler.inputs.sampling_range = 0.0\n",
    "            sampler.inputs.sampling_units = \"mm\"\n",
    "            sampler.inputs.surface = equi_surf_fn_list[depth]\n",
    "            sampler.inputs.out_file = bar_mgh_fn_list[depth][run]\n",
    "\n",
    "            if n_procs == 1:\n",
    "                sampler.run()\n",
    "            else:\n",
    "                sampler.run('MultiProc', plugin_args={'n_procs': n_procs})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed28f8a",
   "metadata": {},
   "source": [
    "### Load preprocessed data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d574380c",
   "metadata": {},
   "source": [
    "Freesurfer meshes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e204db0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if local:\n",
    "    gm_mesh       = surface.load_surf_mesh(gm_surf_fn) \n",
    "    wm_mesh       = surface.load_surf_mesh(wm_surf_fn) \n",
    "    inflated_mesh = surface.load_surf_mesh(inflated_surf_fn) \n",
    "    \n",
    "    inflated_mesh.coordinates.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144eba24",
   "metadata": {},
   "source": [
    "Surface-projected bar data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e714ec05",
   "metadata": {},
   "outputs": [],
   "source": [
    "meanFunc_mgh      = loadVertexDataFile(meanFunc_mgh_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eee1fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "if local and debugging:\n",
    "    bar_mgh_list   = [[loadVertexDataFile(bar_mgh_fn_list[depth][run]) \n",
    "                       for run in range(0,n_runs)] for depth in range(0,n_surfs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36026d3",
   "metadata": {},
   "source": [
    "Check mean functional projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762a8a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "if local:\n",
    "    view = plotting.view_surf(inflated_mesh, meanFunc_mgh,threshold=100,\n",
    "                              bg_map=sulc_surf_fn)\n",
    "    view"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f345ff88",
   "metadata": {},
   "source": [
    "### Make occipital mask\n",
    "(based on surface vertex y-coordinate cut-off, including only posterior vertices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7286aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_coord_cutoff = -60\n",
    "\n",
    "n_vtx = len(meanFunc_mgh[:])\n",
    "n_vtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c52525",
   "metadata": {},
   "outputs": [],
   "source": [
    "occ     = np.zeros(n_vtx)\n",
    "occ[gm_mesh.coordinates[:,1]<y_coord_cutoff]=1.\n",
    "\n",
    "occ_mask = np.nonzero(occ)[0]\n",
    "occ_mask.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1929d4f",
   "metadata": {},
   "source": [
    "Save occipital mask coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a500f32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not local:\n",
    "    if not os.path.exists(occ_mask_fn):\n",
    "        f = open(occ_mask_fn, 'wb')\n",
    "        pickle.dump([occ_mask,n_vtx], f)\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7dc61e",
   "metadata": {},
   "source": [
    "Check occipital mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2737b523",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if local:\n",
    "    view = plotting.view_surf(inflated_mesh, occ, threshold=0.5,\n",
    "                              bg_map=sulc_surf_fn)\n",
    "    view"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beec1b4f",
   "metadata": {},
   "source": [
    "### Clean input data\n",
    "- apply occipital mask to constrain analysis to occipital pole\n",
    "- detrend, standardize, and bandpass filter each functional pRF run\n",
    "- average pRF runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7996b567",
   "metadata": {},
   "outputs": [],
   "source": [
    "detrend     = True\n",
    "standardize = 'zscore'\n",
    "low_pass    = 0.08       # Low pass filters out high frequency signals from our data: \n",
    "                         # fMRI signals are slow evolving processes, any high frequency signals \n",
    "                         # are likely due to noise \n",
    "high_pass   = 0.009      # High pass filters out any very low frequency signals (below 0.009Hz), \n",
    "                         # which may be due to intrinsic scanner instabilities\n",
    "TR          = 3.0        # repetition time (s)\n",
    "\n",
    "confounds   = None       # could add motion regressors here\n",
    "\n",
    "# for details, see: https://nilearn.github.io/dev/modules/generated/nilearn.signal.clean.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edabc9be",
   "metadata": {},
   "source": [
    "Apply occipital mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0ffc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if local and debugging: \n",
    "    masked_bar_mgh_list   = [[bar_mgh_list[depth][run][occ_mask].T\n",
    "                          for run in range(0,n_runs)] for depth in range(0,n_surfs)]\n",
    "    \n",
    "    bar_mgh_list[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9fc6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if local and debugging: \n",
    "    masked_bar_mgh_list[0][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654ca4e8",
   "metadata": {},
   "source": [
    "Detrend, standardize, and bandpass filter each functional pRF run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fbef6fb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'local' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-b671ff93aae4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0mlocal\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdebugging\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     filtered_bar_mgh_list  = [[signal.clean(masked_bar_mgh_list[depth][run],\n\u001b[1;32m      3\u001b[0m                                \u001b[0mconfounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                \u001b[0mdetrend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdetrend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstandardize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstandardize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                \u001b[0mfilter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'butterworth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlow_pass\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlow_pass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhigh_pass\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhigh_pass\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'local' is not defined"
     ]
    }
   ],
   "source": [
    "if local and debugging: \n",
    "    filtered_bar_mgh_list  = [[signal.clean(masked_bar_mgh_list[depth][run],\n",
    "                               confounds=confounds,\n",
    "                               detrend=detrend, standardize=standardize, \n",
    "                               filter='butterworth', low_pass=low_pass, high_pass=high_pass, \n",
    "                               t_r=TR)\n",
    "                               for run in range(0,n_runs)] for depth in range(0,n_surfs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2289b766",
   "metadata": {},
   "source": [
    "Average over runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de23ffcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if local and debugging: \n",
    "    avg_bar_list = [(sum(filtered_bar_mgh_list[depth][:])/len(filtered_bar_mgh_list[depth][:])).T \n",
    "                    for depth in range(0,n_surfs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74891d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if local and debugging: \n",
    "    avg_bar_list[5].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08671389",
   "metadata": {},
   "source": [
    "Average over depths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06dbda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if local and debugging: \n",
    "    avg_bar = sum(avg_bar_list[:])/len(avg_bar_list[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d51fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if local and debugging: \n",
    "    avg_bar.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfbcc14",
   "metadata": {},
   "source": [
    "Plot raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e957f2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vtx = 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd758d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "if local and debugging:\n",
    "    plt.figure(figsize=(7, 5))\n",
    "    plt.plot(masked_bar_mgh_list[0][0][:,vtx],':')\n",
    "    plt.plot(masked_bar_mgh_list[0][1][:,vtx],':')\n",
    "    plt.xlabel('Time [TRs]', fontsize=16)\n",
    "    plt.ylabel('Intensity', fontsize=16)\n",
    "    plt.title('raw data', fontsize=18)\n",
    "    plt.subplots_adjust(bottom=.12, top=.95, right=.95, left=.12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c1fee2",
   "metadata": {},
   "source": [
    "Plot filtered data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257ae638",
   "metadata": {},
   "outputs": [],
   "source": [
    "if local and debugging:\n",
    "    plt.figure(figsize=(7, 5))\n",
    "    plt.plot(filtered_bar_mgh_list[0][0][:,vtx],':')\n",
    "    plt.plot(filtered_bar_mgh_list[0][1][:,vtx],':')\n",
    "    plt.plot((filtered_bar_mgh_list[0][0][:,vtx]+filtered_bar_mgh_list[0][1][:,vtx])/2,'k-')\n",
    "    plt.plot(avg_bar[vtx,:],'r-')\n",
    "    plt.xlabel('Time [TRs]', fontsize=16)\n",
    "    plt.ylabel('Intensity', fontsize=16)\n",
    "    plt.title('filtered data', fontsize=18)\n",
    "    plt.subplots_adjust(bottom=.12, top=.95, right=.95, left=.12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70684eb",
   "metadata": {},
   "source": [
    "### Creating stimulus object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a69585c",
   "metadata": {},
   "source": [
    "Get pRF stimulus aperture file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f56948c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set design mat from aperture file\n",
    "Ap_file            = os.path.join(home_dir,'code','stim-scripts','apertures','stimulus_bar.mat')\n",
    "mat                = scipy.io.loadmat(Ap_file)\n",
    "design_matrix      = mat[\"stim\"]\n",
    "\n",
    "np.shape(design_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa6e2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if local and debugging:    \n",
    "    %matplotlib inline\n",
    "    from IPython.display import clear_output\n",
    "\n",
    "    plt.figure()\n",
    "    for i in range(np.shape(design_matrix)[2]):\n",
    "        plt.imshow(design_matrix[:,:,i],cmap='gist_gray')\n",
    "        plt.title('Frame %d' % (i+1))\n",
    "        plt.show()\n",
    "        clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51d0d9b",
   "metadata": {},
   "source": [
    "Set max eccentricity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de58d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# screen size parameters\n",
    "screen_height_cm   = 12.00\n",
    "screen_size_cm     = screen_height_cm/2 \n",
    "screen_distance_cm = 52.0\n",
    "\n",
    "# calculate max stim ecc\n",
    "max_ecc            = math.atan(screen_size_cm/screen_distance_cm)\n",
    "max_ecc_deg        = math.degrees(max_ecc)\n",
    "max_ecc_deg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47017fb3",
   "metadata": {},
   "source": [
    "Define stimulus object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73a54f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prf_stim = PRFStimulus2D(screen_size_cm=screen_size_cm,\n",
    "                             screen_distance_cm=screen_distance_cm,\n",
    "                             design_matrix=design_matrix,\n",
    "                             TR=TR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b99e7e",
   "metadata": {},
   "source": [
    "## PRF fitting (on data averaged across depths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a02dedd",
   "metadata": {},
   "source": [
    "### Creating Gaussian model and fitter objects\n",
    "\n",
    "Iteratively adjust pRF model parameters (x, y position, pRF size), minimizing the residual sum of squared errors between the prediction and data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8044a79d",
   "metadata": {},
   "source": [
    "##### Define two-dimensional isotropic Gaussian pRF model and model fitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877f974f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input parameters of Iso2DGaussianModel\n",
    "hrf                = None     # string, list or numpy.ndarray, optional\n",
    "                              # HRF shape for this Model.\n",
    "                              # Can be 'direct', which implements nothing (for eCoG or later convolution),\n",
    "                              # a list or array of 3, which are multiplied with the three spm HRF basis functions,\n",
    "                              # and an array already sampled on the TR by the user.\n",
    "                              # (the default is None, which implements standard spm HRF)\n",
    "filter_predictions = False    # boolean, optional\n",
    "                              # whether to high-pass filter the predictions, default False\n",
    "filter_type        = 'sg'\n",
    "\n",
    "sg_filter_window_length = 201\n",
    "sg_filter_polyorder     = 3\n",
    "\n",
    "filter_params      = {'window_length':sg_filter_window_length, \n",
    "                      'polyorder':sg_filter_polyorder}\n",
    "normalize_RFs      = False    # whether or not to normalize the RF volumes (generally not needed).\n",
    "\n",
    "# Input parameters of Iso2DGaussianFitter\n",
    "n_jobs             = n_procs  # int, optional\n",
    "                              # number of jobs to use in parallelization (iterative search), by default 1\n",
    "fit_hrf            = False    # boolean, optional\n",
    "                              # Whether or not to fit two extra parameters for hrf derivative and\n",
    "                              # dispersion. The default is False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fea838",
   "metadata": {},
   "outputs": [],
   "source": [
    "if local and debugging: \n",
    "    # Define 2D iso Gaussian model\n",
    "    gg = Iso2DGaussianModel(stimulus=prf_stim,\n",
    "                              filter_predictions=filter_predictions,\n",
    "                              filter_type=filter_type,\n",
    "                              filter_params=filter_params,\n",
    "                              normalize_RFs=normalize_RFs)\n",
    "    # Define 2D iso Gaussian model fitter\n",
    "    gf = Iso2DGaussianFitter(data=avg_bar, model=gg, n_jobs=n_jobs, fit_css=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aead84a",
   "metadata": {},
   "source": [
    "##### Grid fit\n",
    "\n",
    "First, conduct a quick, coarse model fitting using provided grids and predictor definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb6ae4c",
   "metadata": {},
   "source": [
    "Grid fit parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb9085f",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_nr       = 30\n",
    "max_ecc_size  = round(max_ecc_deg,2)\n",
    "\n",
    "size_grid, ecc_grid, polar_grid = max_ecc_size * np.linspace(0.25,1,grid_nr)**2, \\\n",
    "                    max_ecc_size * np.linspace(0.1,1,grid_nr)**2, \\\n",
    "                        np.linspace(0, 2*np.pi, grid_nr)\n",
    "verbose       = True        # boolean, optional\n",
    "                            # Whether to print output. The default is False."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e03133",
   "metadata": {},
   "source": [
    "Run grid fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a582e0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not local and slurm_run:\n",
    "    if not os.path.exists(grid_fit_avg_fn):\n",
    "        gf.grid_fit(ecc_grid=ecc_grid,\n",
    "                    polar_grid=polar_grid,\n",
    "                    size_grid=size_grid,\n",
    "                    verbose=verbose,\n",
    "                    n_batches=n_procs)\n",
    "    else:\n",
    "        f = open(grid_fit_avg_fn,'rb')\n",
    "        gf = pickle.load(f)\n",
    "        \n",
    "print(\"Finished running grid fit, averaged over depth.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30dfede9",
   "metadata": {},
   "source": [
    "Save grid fit result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b8bd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not local and slurm_run:\n",
    "    if not os.path.exists(grid_fit_avg_fn):\n",
    "        f = open(grid_fit_avg_fn, 'wb')\n",
    "        pickle.dump(gf, f)\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5905a7e0",
   "metadata": {},
   "source": [
    "##### Iterative fit\n",
    "Next, run fine, iterative fit "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c546420b",
   "metadata": {},
   "source": [
    "Iterative fit parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d179432d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterative fit parameters (2D iso Gaussian model)\n",
    "rsq_thresh_itfit = 0.0005   # float\n",
    "                            # Rsq threshold for iterative fitting. Must be between 0 and 1.\n",
    "verbose          = True     # boolean, optional\n",
    "                            # Whether to print output. The default is False."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580e2c85",
   "metadata": {},
   "source": [
    "Run iterative fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535dd693",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not local and slurm_run:\n",
    "    if not os.path.exists(iterative_fit_avg_fn):\n",
    "        gf.iterative_fit(rsq_threshold=rsq_thresh_itfit, verbose=verbose)\n",
    "    else:\n",
    "        f = open(iterative_fit_avg_fn,'rb')\n",
    "        gf = pickle.load(f)\n",
    "print(\"Finished running iterative fit, averaged over depth.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fae20b",
   "metadata": {},
   "source": [
    "Save iterative fit result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcffc8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not local and slurm_run:\n",
    "    if not os.path.exists(iterative_fit_avg_fn):\n",
    "        f = open(iterative_fit_avg_fn, 'wb')\n",
    "        pickle.dump(gf, f)\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2814966",
   "metadata": {},
   "source": [
    "### PRF parameter estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6c45a3",
   "metadata": {},
   "source": [
    "Extract pRF parameter estimates from iterative fit result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c651e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not local and slurm_run:\n",
    "    x=gf.iterative_search_params[:,0]\n",
    "    y=gf.iterative_search_params[:,1]\n",
    "    sigma=gf.iterative_search_params[:,2]\n",
    "    total_rsq = gf.iterative_search_params[:,-1]\n",
    "\n",
    "    #Calculate polar angle and eccentricity maps\n",
    "    polar = np.angle(x + 1j*y)\n",
    "    ecc = np.abs(x + 1j*y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac048b85",
   "metadata": {},
   "source": [
    "Save pRF parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068db9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not local and slurm_run:\n",
    "    if not os.path.exists(pRF_param_avg_fn):\n",
    "        f = open(pRF_param_avg_fn, 'wb')\n",
    "        pickle.dump([x, y, sigma, total_rsq, polar, ecc], f)\n",
    "        f.close()\n",
    "elif local:\n",
    "    if os.path.exists(pRF_param_avg_fn):\n",
    "        f = open(pRF_param_avg_fn,'rb')\n",
    "        x, y, sigma, total_rsq, polar, ecc = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6b2ce2",
   "metadata": {},
   "source": [
    "# PRF fitting (per depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accc6485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input parameters of Iso2DGaussianModel\n",
    "hrf                = None     # string, list or numpy.ndarray, optional\n",
    "                              # HRF shape for this Model.\n",
    "                              # Can be 'direct', which implements nothing (for eCoG or later convolution),\n",
    "                              # a list or array of 3, which are multiplied with the three spm HRF basis functions,\n",
    "                              # and an array already sampled on the TR by the user.\n",
    "                              # (the default is None, which implements standard spm HRF)\n",
    "filter_predictions = False    # boolean, optional\n",
    "                              # whether to high-pass filter the predictions, default False\n",
    "filter_type        = 'sg'\n",
    "\n",
    "sg_filter_window_length = 201\n",
    "sg_filter_polyorder     = 3\n",
    "\n",
    "filter_params      = {'window_length':sg_filter_window_length, \n",
    "                      'polyorder':sg_filter_polyorder}\n",
    "normalize_RFs      = False    # whether or not to normalize the RF volumes (generally not needed).\n",
    "\n",
    "# Input parameters of Iso2DGaussianFitter\n",
    "n_jobs             = n_procs  # int, optional\n",
    "                              # number of jobs to use in parallelization (iterative search), by default 1\n",
    "fit_hrf            = True    # boolean, optional\n",
    "                              # Whether or not to fit two extra parameters for hrf derivative and\n",
    "                              # dispersion. The default is False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ab63fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if local and debugging: \n",
    "    # Define 2D iso Gaussian model\n",
    "    gg = Iso2DGaussianModel(stimulus=prf_stim,\n",
    "                              filter_predictions=filter_predictions,\n",
    "                              filter_type=filter_type,\n",
    "                              filter_params=filter_params,\n",
    "                              normalize_RFs=normalize_RFs) \n",
    "\n",
    "    # Define 2D iso Gaussian model fitter\n",
    "    gf_per_depth = [Iso2DGaussianFitter(data=avg_bar_list[depth], \n",
    "                                        model=gg, n_jobs=n_jobs, \n",
    "                                        fit_css=False, \n",
    "                                        previous_gaussian_fitter=gf) for depth in range(0,n_surfs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eccf442",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Now running running grid fit per depth.\")\n",
    "\n",
    "if not local and slurm_run:\n",
    "    if not os.path.exists(grid_fit_per_depth_fn):\n",
    "        for depth in range(0,n_surfs):\n",
    "            print(depth)\n",
    "            gf_per_depth[depth].grid_fit(ecc_grid=ecc_grid,\n",
    "                                         polar_grid=polar_grid,\n",
    "                                         size_grid=size_grid,\n",
    "                                         verbose=verbose,\n",
    "                                         n_batches=n_procs)\n",
    "    else:\n",
    "        f = open(grid_fit_per_depth_fn,'rb')\n",
    "        gf = pickle.load(f)\n",
    "\n",
    "if not local and slurm_run:\n",
    "    if not os.path.exists(grid_fit_per_depth_fn):\n",
    "        f = open(grid_fit_per_depth_fn, 'wb')\n",
    "        pickle.dump(gf_per_depth, f)\n",
    "        f.close()\n",
    "\n",
    "print(\"Now running iterative fit per depth.\")\n",
    "\n",
    "if not local and slurm_run:\n",
    "    if not os.path.exists(iterative_fit_per_depth_fn):\n",
    "        for depth in range(0,n_surfs):\n",
    "            print(depth)\n",
    "            gf_per_depth[depth].iterative_fit(rsq_threshold=rsq_thresh_itfit, verbose=verbose)\n",
    "    else:\n",
    "        f = open(iterative_fit_per_depth_fn,'rb')\n",
    "        gf = pickle.load(f)\n",
    "\n",
    "if not local and slurm_run:\n",
    "    if not os.path.exists(iterative_fit_per_depth_fn):\n",
    "        f = open(iterative_fit_per_depth_fn, 'wb')\n",
    "        pickle.dump(gf_per_depth, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae7f832",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(iterative_fit_avg_fn,'rb')\n",
    "gf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaeae0d5",
   "metadata": {},
   "source": [
    "### PRF parameter estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becfe19e",
   "metadata": {},
   "source": [
    "Extract pRF parameter estimates from iterative fit result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b100ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not local and slurm_run:\n",
    "    x_per_depth = [gf_per_depth[depth].iterative_search_params[:,0] for depth in range(0,n_surfs)]\n",
    "    y_per_depth = [gf_per_depth[depth].iterative_search_params[:,1] for depth in range(0,n_surfs)]\n",
    "    sigma_per_depth = [gf_per_depth[depth].iterative_search_params[:,2] for depth in range(0,n_surfs)]\n",
    "    total_rsq_per_depth = [gf_per_depth[depth].iterative_search_params[:,-1] for depth in range(0,n_surfs)]\n",
    "\n",
    "    #Calculate polar angle and eccentricity maps\n",
    "    polar_per_depth = [np.angle(x_per_depth[depth] + 1j*y_per_depth[depth]) for depth in range(0,n_surfs)]\n",
    "    ecc_per_depth = [np.abs(x_per_depth[depth] + 1j*y_per_depth[depth]) for depth in range(0,n_surfs)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fe8387",
   "metadata": {},
   "source": [
    "Save pRF parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551ece76",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not local and slurm_run:\n",
    "    if not os.path.exists(pRF_param_per_depth_fn):\n",
    "        f = open(pRF_param_per_depth_fn, 'wb')\n",
    "        pickle.dump([x_per_depth, y_per_depth, sigma_per_depth, total_rsq_per_depth, polar_per_depth, ecc_per_depth], f)\n",
    "        f.close()\n",
    "elif local:\n",
    "    if os.path.exists(pRF_param_per_depth_fn):\n",
    "        f = open(pRF_param_per_depth_fn,'rb')\n",
    "        x_per_depth, y_per_depth, sigma_per_depth, total_rsq_per_depth, polar_per_depth, ecc_per_depth = pickle.load(f)\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17b1f11",
   "metadata": {},
   "source": [
    "## PRF mapping results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1c58a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(occ_mask_fn,'rb')\n",
    "occ_mask,n_vtx = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65423acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "occ_mask.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2884612",
   "metadata": {},
   "source": [
    "\"Unmask\" pRF mapping parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcde566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg\n",
    "unmask_x               = np.zeros(n_vtx)\n",
    "unmask_y               = np.zeros(n_vtx)\n",
    "unmask_sigma           = np.zeros(n_vtx)\n",
    "unmask_rsq             = np.zeros(n_vtx)\n",
    "unmask_polar           = np.zeros(n_vtx)\n",
    "unmask_ecc             = np.zeros(n_vtx)\n",
    "\n",
    "unmask_x[occ_mask]     = x\n",
    "unmask_y[occ_mask]     = y\n",
    "unmask_sigma[occ_mask] = sigma\n",
    "unmask_rsq[occ_mask]   = total_rsq\n",
    "unmask_polar[occ_mask] = polar\n",
    "unmask_ecc[occ_mask]   = ecc\n",
    "\n",
    "\n",
    "# per depth\n",
    "unmask_x_per_depth     = [np.zeros(n_vtx) for depth in range(0,n_surfs)]\n",
    "unmask_y_per_depth     = [np.zeros(n_vtx) for depth in range(0,n_surfs)]\n",
    "unmask_sigma_per_depth = [np.zeros(n_vtx) for depth in range(0,n_surfs)]\n",
    "unmask_rsq_per_depth   = [np.zeros(n_vtx) for depth in range(0,n_surfs)]\n",
    "unmask_polar_per_depth = [np.zeros(n_vtx) for depth in range(0,n_surfs)]\n",
    "unmask_ecc_per_depth   = [np.zeros(n_vtx) for depth in range(0,n_surfs)]\n",
    "\n",
    "for depth in range(0,n_surfs):\n",
    "    unmask_x_per_depth[depth][occ_mask]     = x_per_depth[depth]\n",
    "    unmask_y_per_depth[depth][occ_mask]     = y_per_depth[depth]\n",
    "    unmask_sigma_per_depth[depth][occ_mask] = sigma_per_depth[depth]\n",
    "    unmask_rsq_per_depth[depth][occ_mask]   = total_rsq_per_depth[depth]\n",
    "    unmask_polar_per_depth[depth][occ_mask] = polar_per_depth[depth]\n",
    "    unmask_ecc_per_depth[depth][occ_mask]   = ecc_per_depth[depth]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f39c3a",
   "metadata": {},
   "source": [
    "Threshold pRF maps by rsq, constrain to realistic eccentricities & pRF sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe4e4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rsq_thresh = 0.1\n",
    "pRF_thresh = max_ecc_deg        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2657a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove bad fits -avg\n",
    "unmask_x[unmask_rsq<rsq_thresh]     = np.nan\n",
    "unmask_y[unmask_rsq<rsq_thresh]     = np.nan\n",
    "unmask_sigma[unmask_rsq<rsq_thresh] = np.nan\n",
    "unmask_polar[unmask_rsq<rsq_thresh] = np.nan\n",
    "unmask_ecc[unmask_rsq<rsq_thresh]   = np.nan\n",
    "\n",
    "# remove bad fits - per depth\n",
    "for depth in range(0,n_surfs):\n",
    "    unmask_x_per_depth[depth][unmask_rsq_per_depth[depth]<rsq_thresh]     = np.nan\n",
    "    unmask_y_per_depth[depth][unmask_rsq_per_depth[depth]<rsq_thresh]     = np.nan\n",
    "    unmask_sigma_per_depth[depth][unmask_rsq_per_depth[depth]<rsq_thresh] = np.nan\n",
    "    unmask_polar_per_depth[depth][unmask_rsq_per_depth[depth]<rsq_thresh] = np.nan\n",
    "    unmask_ecc_per_depth[depth][unmask_rsq_per_depth[depth]<rsq_thresh]   = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51081b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg\n",
    "# remove vertices where eccentricity is larger than max stimulus ecc\n",
    "unmask_x[unmask_ecc>max_ecc_deg]     = np.nan\n",
    "unmask_y[unmask_ecc>max_ecc_deg]     = np.nan\n",
    "unmask_polar[unmask_ecc>max_ecc_deg] = np.nan\n",
    "unmask_sigma[unmask_ecc>max_ecc_deg] = np.nan\n",
    "unmask_ecc[unmask_ecc>max_ecc_deg]   = np.nan\n",
    "\n",
    "# remove vertices where pRF size is negative\n",
    "unmask_x[unmask_sigma<0]     = np.nan\n",
    "unmask_y[unmask_sigma<0]     = np.nan\n",
    "unmask_polar[unmask_sigma<0] = np.nan\n",
    "unmask_ecc[unmask_sigma<0]   = np.nan\n",
    "unmask_sigma[unmask_sigma<0] = np.nan\n",
    "\n",
    "# set max pRF size to max stimulus eccentricity\n",
    "unmask_x[unmask_sigma>pRF_thresh]     = np.nan\n",
    "unmask_y[unmask_sigma>pRF_thresh]     = np.nan\n",
    "unmask_polar[unmask_sigma>pRF_thresh] = np.nan\n",
    "unmask_ecc[unmask_sigma>pRF_thresh]   = np.nan\n",
    "unmask_sigma[unmask_sigma>pRF_thresh] = np.nan\n",
    "\n",
    "\n",
    "\n",
    "# per depth\n",
    "for depth in range(0,n_surfs):\n",
    "    # remove vertices where eccentricity is larger than max stimulus ecc\n",
    "    unmask_x_per_depth[depth][unmask_ecc_per_depth[depth]>max_ecc_deg]     = np.nan\n",
    "    unmask_y_per_depth[depth][unmask_ecc_per_depth[depth]>max_ecc_deg]     = np.nan\n",
    "    unmask_polar_per_depth[depth][unmask_ecc_per_depth[depth]>max_ecc_deg] = np.nan\n",
    "    unmask_sigma_per_depth[depth][unmask_ecc_per_depth[depth]>max_ecc_deg] = np.nan\n",
    "    unmask_ecc_per_depth[depth][unmask_ecc_per_depth[depth]>max_ecc_deg]   = np.nan\n",
    "\n",
    "    # remove vertices where pRF size is negative\n",
    "    unmask_x_per_depth[depth][unmask_sigma_per_depth[depth]<0]     = np.nan\n",
    "    unmask_y_per_depth[depth][unmask_sigma_per_depth[depth]<0]     = np.nan\n",
    "    unmask_polar_per_depth[depth][unmask_sigma_per_depth[depth]<0] = np.nan\n",
    "    unmask_ecc_per_depth[depth][unmask_sigma_per_depth[depth]<0]   = np.nan\n",
    "    unmask_sigma_per_depth[depth][unmask_sigma_per_depth[depth]<0] = np.nan\n",
    "\n",
    "    # set max pRF size to max stimulus eccentricity\n",
    "    unmask_x_per_depth[depth][unmask_sigma_per_depth[depth]>pRF_thresh]     = np.nan\n",
    "    unmask_y_per_depth[depth][unmask_sigma_per_depth[depth]>pRF_thresh]     = np.nan\n",
    "    unmask_polar_per_depth[depth][unmask_sigma_per_depth[depth]>pRF_thresh] = np.nan\n",
    "    unmask_ecc_per_depth[depth][unmask_sigma_per_depth[depth]>pRF_thresh]   = np.nan\n",
    "    unmask_sigma_per_depth[depth][unmask_sigma_per_depth[depth]>pRF_thresh] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9e5807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg\n",
    "unmask_x[np.isnan(unmask_x)]         = 0.\n",
    "unmask_y[np.isnan(unmask_y)]         = 0.\n",
    "unmask_polar[np.isnan(unmask_polar)] = 0.\n",
    "unmask_ecc[np.isnan(unmask_ecc)]     = 0.\n",
    "unmask_sigma[np.isnan(unmask_sigma)] = 0.\n",
    "\n",
    "# per depth\n",
    "for depth in range(0,n_surfs):\n",
    "    unmask_x_per_depth[depth][np.isnan(unmask_x_per_depth[depth])]         = 0.\n",
    "    unmask_y_per_depth[depth][np.isnan(unmask_y_per_depth[depth])]         = 0.\n",
    "    unmask_polar_per_depth[depth][np.isnan(unmask_polar_per_depth[depth])] = 0.\n",
    "    unmask_ecc_per_depth[depth][np.isnan(unmask_ecc_per_depth[depth])]     = 0.\n",
    "    unmask_sigma_per_depth[depth][np.isnan(unmask_sigma_per_depth[depth])] = 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a77796",
   "metadata": {},
   "source": [
    "### Plots for average across depth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac275cc",
   "metadata": {},
   "source": [
    "##### Polar angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd11602b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if hem_list[hem_id] == 'lh':\n",
    "    view = plotting.view_surf(inflated_mesh, unmask_polar,threshold=0.1,\n",
    "                              bg_map=sulc_surf_fn,vmax=np.pi,vmin=np.pi/2,\n",
    "                             cmap='RdYlBu')\n",
    "elif hem_list[hem_id] == 'rh':\n",
    "    view = plotting.view_surf(inflated_mesh, unmask_polar,threshold=0.1,\n",
    "                              bg_map=sulc_surf_fn,vmax=np.pi/2,vmin=-np.pi/2,\n",
    "                             cmap='Spectral')\n",
    "view"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aed3665",
   "metadata": {},
   "source": [
    "##### Eccentricity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed99e596",
   "metadata": {},
   "outputs": [],
   "source": [
    "view = plotting.view_surf(inflated_mesh, unmask_ecc,threshold=0.01,\n",
    "                          bg_map=sulc_surf_fn,vmax=max_ecc_deg,vmin=0,\n",
    "                          cmap='plasma', symmetric_cmap=False)\n",
    "view"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a652222",
   "metadata": {},
   "source": [
    "##### PRF size (sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b94186",
   "metadata": {},
   "outputs": [],
   "source": [
    "view = plotting.view_surf(inflated_mesh, unmask_sigma,threshold=0.01,\n",
    "                          bg_map=sulc_surf_fn,vmax=max_ecc_deg/2,vmin=0,\n",
    "                          cmap='plasma', symmetric_cmap=False)\n",
    "view"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1512939f",
   "metadata": {},
   "source": [
    "### Plots per depth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d142b87",
   "metadata": {},
   "source": [
    "##### PRF size (sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86439836",
   "metadata": {},
   "outputs": [],
   "source": [
    "view = plotting.view_surf(inflated_mesh, unmask_sigma_per_depth[5],threshold=0.01,\n",
    "                          bg_map=sulc_surf_fn,vmax=max_ecc_deg/2,vmin=0,\n",
    "                          cmap='plasma', symmetric_cmap=False)\n",
    "view"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de25a84c",
   "metadata": {},
   "source": [
    "### Save maps to .mgh files for manual delineations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e57314",
   "metadata": {},
   "outputs": [],
   "source": [
    "#meanFunc_mgh_nib = nib.freesurfer.mghformat.load(meanFunc_mgh_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2971f6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#affine = meanFunc_mgh_nib.get_affine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950ef556",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nib.save(nib.freesurfer.mghformat.MGHImage(unmask_polar.astype(np.float32, order = \"C\"),affine=affine),polar_map_mgh)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f8874f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#polar_map_mgh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867ab214",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nib.save(nib.freesurfer.mghformat.MGHImage(unmask_ecc.astype(np.float32, order = \"C\"),affine=affine),ecc_map_mgh)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
